{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "lr = LogisticRegression()\n",
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier()\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc, cohen_kappa_score\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = pd.read_excel('./LIWC2015 Results (training data_clean).xlsx')\n",
    "#TF: TopicFeatures\n",
    "#LF: boarder LinguisticFeatures\n",
    "#LSF: LanguageSummaryFeatures, LIWC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**roc_auc value: micro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the y_score for each classifier, the variable is the classifier type\n",
    "#for svm and logisticRegression only\n",
    "def get_y_score(method):\n",
    "    classifier = OneVsRestClassifier(method)\n",
    "    y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "    return y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a dictionary of micro roc_auc value\n",
    "#micro: \n",
    "#the return value has the roc_value for each class, and the avg roc_auc value for all classes\n",
    "def get_micro_auc(y_score):\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:,i], y_score[:,i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    fpr['micro'], tpr['micro'], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc['micro'] = auc(fpr['micro'], tpr['micro'])\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For decision trees & Bayes\n",
    "def get_y_score_for_tree(method):\n",
    "    classifier = OneVsRestClassifier(method)\n",
    "    y_score = classifier.fit(X_train, y_train).predict_proba(X_test)\n",
    "    return y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature selections\n",
    "\n",
    "samplefile = file.sample(n = 800,replace=True) #take 800 as samples\n",
    "    \n",
    "# use those features and their combination as X to generate desireable result and write them down seperately \n",
    "\n",
    "X = samplefile.iloc[:,2:10] # only LIWC features-----LSF\n",
    "   \n",
    "#y = file['code']\n",
    "# X = samplefile.iloc[:,10:43] # only Grammers features\n",
    "#X = samplefile.iloc[:,43:79] # only Linguistic Feature\n",
    "#X = samplefile.iloc[:,2:79] #LF + LSF\n",
    "#X = samplefile.iloc[:,10:79] # Grammer + Linguistic = broader Linguistic features-----LF\n",
    "#X = samplefile.iloc[:,79:] # only Topic Featurs----TF\n",
    "#X = samplefile.iloc[:,43:] #Topic Features + Linguistic Features\n",
    "#X = samplefile.iloc[:,2:] # all features combined----LSF + LF + TF\n",
    "y = samplefile['code']\n",
    "y = label_binarize(y, classes = [0,1,2,3,4])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "n_classes = y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "{0: 0.898971247691902, 1: 0.7995151515151515, 2: 0.7440965915161876, 3: 0.8267336112163699, 4: 0.8259590636107366, 'micro': 0.8335677083333333}\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "lr_y_score = get_y_score(lr)\n",
    "lr_roc = get_micro_auc(lr_y_score)\n",
    "print \"Logistic Regression\"\n",
    "print lr_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "{0: 0.9434186230546031, 1: 0.8898989898989899, 2: 0.9024468426113901, 3: 0.9054566123531641, 4: 0.886260571148425, 'micro': 0.9055468749999999}\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "svm_y_score = get_y_score(svc)\n",
    "svm_roc = get_micro_auc(svm_y_score)\n",
    "print \"SVM\"\n",
    "print svm_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Trees\n",
      "{0: 0.7806647322606174, 1: 0.7587878787878788, 2: 0.8231114435302918, 3: 0.7961348995831754, 4: 0.7280916779017037, 'micro': 0.7848958333333333}\n"
     ]
    }
   ],
   "source": [
    "#For decision trees\n",
    "print \"Decision Trees\"\n",
    "dtc_y_score = get_y_score_for_tree(dtc)\n",
    "print get_micro_auc(dtc_y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes\n",
      "{0: 0.7942495383803747, 1: 0.7767272727272727, 2: 0.5946148092744951, 3: 0.7248957938613112, 4: 0.6780242676798628, 'micro': 0.7244487847222223}\n"
     ]
    }
   ],
   "source": [
    "#For Naive Bayes\n",
    "print \"Naive Bayes\"\n",
    "gb_y_score = get_y_score_for_tree(gnb)\n",
    "print get_micro_auc(gb_y_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**kappa value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predict(method):\n",
    "    classifier = OneVsRestClassifier(method)\n",
    "    y_pred = classifier.fit(X_train, y_train).predict(X_test)\n",
    "    return y_pred    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kappa_score(y_pred):\n",
    "    kappa = dict()\n",
    "    for i in range(n_classes):\n",
    "        kappa[i] = cohen_kappa_score(y_test[:,i], y_pred[:,i])\n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "{0: 0.0, 1: 0.13081081081081092, 2: 0.01670951156812328, 3: 0.0938098276962348, 4: 0.02751119641714661}\n",
      "Avg\n",
      "0.05376826929846312\n"
     ]
    }
   ],
   "source": [
    "#LogisticRegression\n",
    "lr_pred = get_predict(lr)\n",
    "print \"Logistic Regression\"\n",
    "print get_kappa_score(lr_pred)\n",
    "print \"Avg\"\n",
    "print np.mean(get_kappa_score(lr_pred).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "{0: 0.6764408493427705, 1: 0.5151515151515151, 2: 0.6065036207132122, 3: 0.49320148331273184, 4: 0.5631067961165048}\n",
      "Avg\n",
      "0.5708808529273469\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "svm_pred = get_predict(svc)\n",
    "print \"SVM\"\n",
    "svm_kappa = get_kappa_score(svm_pred)\n",
    "print svm_kappa\n",
    "print \"Avg\"\n",
    "print np.mean(svm_kappa.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Trees\n",
      "{0: 0.5478723404255319, 1: 0.49211618257261414, 2: 0.5294616362865621, 3: 0.5525044495296212, 4: 0.5425459496255957}\n",
      "Avg\n",
      "0.532900111687985\n"
     ]
    }
   ],
   "source": [
    "#Decision Trees\n",
    "dtc_pred = get_predict(dtc)\n",
    "print \"Decision Trees\"\n",
    "dtc_kappa = get_kappa_score(dtc_pred)\n",
    "print dtc_kappa\n",
    "print \"Avg\"\n",
    "print np.mean(dtc_kappa.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayes\n",
      "{0: 0.13842619184376792, 1: -0.0117647058823529, 2: 0.10802062102865373, 3: 0.2737588652482269, 4: 0.16422900125365658}\n",
      "Avg\n",
      "0.13453399469839045\n"
     ]
    }
   ],
   "source": [
    "#Bayes\n",
    "gnb_pred = get_predict(gnb)\n",
    "print \"Bayes\"\n",
    "gnb_kappa = get_kappa_score(gnb_pred)\n",
    "print gnb_kappa\n",
    "print \"Avg\"\n",
    "print np.mean(gnb_kappa.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
